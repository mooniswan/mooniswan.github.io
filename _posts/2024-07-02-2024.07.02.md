---
title: 2024.07.02
description: 딥러닝 학습방법과 확률통계(베이즈 통계학)를 공부합니다.
categories: [TIL, Machine Learning]
tags: [til, machine learning, deep learning, softmax, Bayesian Statistics]
date: 2024-07-02 22:15:00 +0900
math: true
---

<hr>
* softmax 함수 
: 모델의 출력을 확률로 해석하는 함수 <br/>
'분류' 문제를 풀 때, 선형모델(O = Wx + b)과 소프트맥스 함수를 결합해 예측함. <br/>

```python
def softmax(vec):
    denumerator = np.exp(vec - np.max(vec, axis=-1, keepdims=True))
    numerator = np.sum(denumerator, axis=-1, keepdims=True)
    val = denumerator / numerator
    return val
```
{: .nolineno }

$$
softmax(o) = softmax(Wx + b)
$$ 

'추론'을 할 때는, 원-핫(one-hot)벡터로 최대값을 가진 주소만 1로 출력하는 연산 사용함. <br/>

* 신경망 <br/>
: 선형모델과 활성함수(activation function)를 합성한 함수 <br/>

* 활성함수 <br/>
: R 위에 정의된 비선형(nonlinear) 함수 (Ex, ReLU ...) <br/>

* 다층 퍼셉트론(MLP) <br/>
: 신경망이 여러층 합성된 함수 <br/>
층이 깊을수록 목적함수를 근사하는데 필요한 뉴런(노드)의 숫자가 훨씬 빨리 줄어들기 때문에 더 효율적으로 학습 가능

* 역전파(backpropagation)알고리즘 <br/>
: 합성함수 미분법인 연쇄법칙(chain-rule) 기반 자동미분을 사용함 <br/>

각 노드의 텐서 값을 미리 메모리에 저장을 해야만 미분 계산이 가능

<hr>

<h3> 확률통계 </h3>

1. 회귀분석
: 손실함수로 사용되는 L_2 norm => 예측오차의 분산을 가장 최소화하는 방향으로 학습 <br/>
2. 분류문제
: 교차엔트로피(cross-entropy) => 모델 예측의 불확실성을 최소화하는 방향으로 학습 <br/>

확률변수는 확률분포 D에 따라 이산형(discrete), 연속형(continuous)으로 구분 <br/>

`이산형` <br/>
: 확률변수가 가질 수 있는 경우의 수 즉, 확률을 더해 모델링
$$
{P}(X \in A) = \sum_{x \in A} {P}(X = x)
$$ 
<br/>

`연속형` <br/>
: 데이터 공간에 정의된 확률변수의 밀도(density) 위에서 적분을 통해 모델링 <br/>
$$
b{P}(X \in A) = \int_{A} P(x) \, dx
$$

결합분포 P(x,y)는 D를 모델링 <br/>

* 조건부확률 P(y|x) <br/>
: 입력변수 x에 대해 정답이 y일 확률 <br/>

기계학습에서 확률분포를 모를 때, <br/>
=> 데이터를 이용해 기대값을 계산하려면 '몬테카를로 샘플링' 방법을 사용해야 함 <br/>
=> 독립추출이 보장되면 대수의 법칙에 의해 수렴성 보장됨 <br/> <br/>
<hr>
1. 모수적(parametric) 방법론
: 특정 확률분포를 따른다고 가정한 후 분포를 결정하는 모수 추정 <br/>
2. 비모수적(nonparametric) 방법론
: 특정 확률분포 가정x, 유연하게 바뀜 <br/>

* 중심극한 정리
: 모집단의 분포가 정규분포를 따르지 않아도, 표본평균의 표집분포(통계량의 확률분포)는 N이 커질수록 정규분포를 따름

* 최대가능도 추정법(maximum likelihood estimation_<b>MLE</b>) 
: 가장 가능성이 높은 모수를 추정하는 방법 중 하나 <br/>
-> 데이터 집합 X가 독립적으로 추출되었을 경우 로그가능도를 최적화함 <br/>

<span style="color:red;">why 로그가능도? </span> <br/>
데이터가 매우 많으면, 로그를 사용해 가능도의 곱셉 -> 로그가능도의 덧셈으로 변환 가능 <br/>
경사하강법으로 가능도를 최적화할 때 미분 연산을 사용하는데, 로그 가능도 사용 시 연산량을 $$ O(n^2) $$ 에서 $$ O(n) $$ 으로 줄여줌 <br/>
대게 손실함수의 경우 음의 로그가능도 최적화 <br/>

* 딥러닝에서 최대가능도 추정법
=> 기계학습 모델 학습 <br/>
: 딥러닝 모델의 가중치를 $$ theta = ({W}^{(1)}, ..., W^{(L)}) $$ 라 표기했을 때, 분류 문제에서 softmax vector는 카테고리 분포의 모수 $$ (p_1, ...,p_k) $$ 를 모델링함 <br/>

$$
\hat{\theta}_{\text{MLE}} = \arg\max_{\theta} \frac{1}{n} \sum_{i=1}^{n} \sum_{k=1}^{K} y_{i,k} \log(\text{MLP}_{\theta}(x_i)_k)
$$

기계학습에서의 손실함수 <br/>
:  모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도 <br/>
두 개의 확률 분포 P(x), Q(x) 가 있을 때,
두 확률분포 사이의 distance를 계산할 때 다음과 같은 함수 이용 <br/>
1. 총변동 거리(TV)
2. 쿨백-라이블러 발산(KL Divergence) 
> 분류 문제에서 최대가능도 추정법은 쿨백-라이블러 발산을 최소화
3. 바슈타인 거리(Wasserstein Distance)

<hr>

* <span style="color:red;"> 베이즈 정리 </span> <br/>
: 조건부확률을 이용해, 정보를 갱신하는 방법을 알려줌 <br/>
 
$$
P(\theta | \mathcal{D}) = P(\theta) \frac{P(\mathcal{D} | \theta)}{P(\mathcal{D})}
$$

사후확률 = 사전확률 x (Likelihood/Evidence(데이터 전체의 분포)) <br/>
<br/>

<b> <span style="color:blue;"> if 코로나 발병률 10%, 실제로 걸렸을 때 검진될 확률 99%, 실제로 걸리지 않았을 때 오검진될 확률 1% 일 때, </span> </b> <br/> 
질병에 걸렸다고 검진결과가 나왔을 때 정말로 감염되었을 확률은? <br/>

<b>Evidence</b> = likelihood 이용해 계산 <br/>
P(D) = 0.99 x 0.1(사전확률) + 0.01 x <span style="color:red;"> 0.9(-사전확률) </span> = 0.108

$$
P(\theta | \mathcal{D}) = 0.1 × 0.99/0.108 ≈ 0.916
$$

False alarm(오탐율)이 오르면, 테스트의 Precision이 떨어짐

앞서 계산한 사후확률을 사전확률로 사용해 갱신된 사후확률을 계산할 수 있음 <br/>
=> 데이터를 새로 관측할때마다 모델의 파라미터를 업데이트해 예측력 향상 <br/>

> 조건부 확률을 인과관계를 추론할 때 함부로 사용해서는 안 됨
{: .prompt-warning }

인과관계
: 데이터 분포의 변화에 강건한 예측모형을 만들 때 필요함 <br/>
: 중첩요인(confounding factor)의 효과를 제거하고 원인 변수만의 인과관계를 계산해야 함 <br/>

* 인과관계 추론 <br/>
<b> Q. 치료법 a or b 중 뭐가 더 나은가? </b> <br/>
조정(intervention) 효과를 통해 Z(신장 결석 크기)의 개입을 제거하는 인과관계 분석함 <br/>
=> 조건부확률로 계산한 치료효과와 정반대의 결과가 나오게 됨(더 신뢰된 결과 도출) 
<br/>
<br/>

> 네이버 boostcourse의 인공지능 기초 다지기 강의를 참조함