---
title: 2024.06.30
description: 머신러닝을 다루기 위한 기초수학을 공부합니다.
categories: [TIL, Machine Learning]
tags: [til, machine learning, mathematics]
date: 2024-06-30 13:00:00 +0900
---
 
<h2> 벡터 </h2>

: 숫자를 원소로 가지는 리스트 or 배열 <br/>
== 원점에서의 상대적 위치 <br/>

벡터의 노름: 원점에서의 거리 <br/>
L1 norm: 각 성분의 변화량 절대값의 합 <br/>
L2 norm: 유클리드 거리(성분곱의 합에 제곱근 연산) <br/>
=> 기하학적 성질에 따라 두가지 모두 사용 <br/>
<span style="color:yellow;"> 
L1 norm 상의 원 => Robust 학습, Lasso 회귀 <br/>
L2 norm 상의 원 => Laplace 근사, Ridge 회귀
</span>

```python
def l1_norm(x):
    x_norm = np.abs(x) #절댓값
    x_norm = np.sum(x_norm)
    return x_norm

def l2_norm(x):
    x_norm = x*x
    x_norm = np.sum(x_norm)
    x_norm = np.sqrt(x_norm) #제곱근
    return x_norm
# 또는 np.linalg.norm(x)
``` 

* <b> 두 벡터 사이의 <span style="color: red;"> 거리</span></b> => 유클리드 거리 사용 <br/>
즉, 벡터의 뺄셈 이용 (순서 바뀌어도 결과는 동일) <br/>
1. Numpy 라이브러리 이용
```python
dist = np.linalg.norm(a - b) #L2 norm
```
2. scipy 라이브러리의 distance 모듈 이용
```python
dist = distance.euclidean(a, b)
```

* <b> 두 벡터 사이의<span style="color: red;"> 각도</span></b> 
=> L2 norm만 가능
```python
# 라디안 단위 각도 계산
def angle(x, y):
    v = np.inner(x, y) / (l2_norm(x)*l2_norm(y)) # 분자:inner product(내적)
    theta = np.arccos(v) #코사인의 역함수, 즉, 주어진 코사인 값에 해당하는 각 반환
    return theta
```

* 내적(inner product) <br/>
: 정사영(orthogonal projection)의 길이를 벡터 y의 길이만큼 조정한 값 <br/>
<span style="color:yellow;"> => 벡터 간의 유사도 측정시 사용</span> <br/>
== ||y|| Proj(x) <br/>

Proj(x) == ||x||cosθ <br/>
== 벡터 y로 정사영된 벡터 x의 그림자
```python
dot_product = np.dot(a, b)
```

<hr/>